# Azure OpenAI Object Structure

Integrating Azure OpenAI Service with your application allows you to seamlessly utilize multiple deployments and region models hosted by Azure OpenAI. This section details how to configure the Azure OpenAI endpoint for your needs. 

**[For a detailed guide on setting up Azure OpenAI configurations, click here](./azure_openai.md)** //TODO

## Example Configuration

```yaml filename="Example Azure OpenAI Object Structure"
endpoints:
  azureOpenAI:
    titleModel: "gpt-4-turbo"
    plugins: true
    groups:
      - group: "my-westus" # arbitrary name
        apiKey: "${WESTUS_API_KEY}"
        instanceName: "actual-instance-name" # name of the resource group or instance
        version: "2023-12-01-preview"
        # baseURL: https://prod.example.com
        # additionalHeaders:
        #   X-Custom-Header: value
        models:
          gpt-4-vision-preview:
            deploymentName: gpt-4-vision-preview
            version: "2024-02-15-preview"
          gpt-3.5-turbo:
            deploymentName: gpt-35-turbo
          gpt-3.5-turbo-1106:
            deploymentName: gpt-35-turbo-1106
          gpt-4:
            deploymentName: gpt-4
          gpt-4-1106-preview:
            deploymentName: gpt-4-1106-preview
      - group: "my-eastus"
        apiKey: "${EASTUS_API_KEY}"
        instanceName: "actual-eastus-instance-name"
        deploymentName: gpt-4-turbo
        version: "2024-02-15-preview"
        baseURL: "https://gateway.ai.cloudflare.com/v1/cloudflareId/azure/azure-openai/${INSTANCE_NAME}/${DEPLOYMENT_NAME}" # uses env variables
        additionalHeaders:
          X-Custom-Header: value
        models:
          gpt-4-turbo: true
```

## plugins

**Key:**
<OptionTable
  options={[
    ['plugins', 'Boolean', 'Enables or disables plugins for the Azure OpenAI endpoint. When set to `true`, it activates any plugins associated with this endpoint, allowing the system to use additional features or functionality provided by the plugins.', 'Choose one, either the official OpenAI API or Azure OpenAI API for plugins, not both.'],
  ]}
/>

**Default:** Not specified

**Example:**
```yaml filename="plugins"
plugins: true
```

## assistants

**Key:**
<OptionTable
  options={[
    ['assistants', 'Boolean', 'Enables or disables assistants for the Azure OpenAI endpoint. When set to `true`, activates assistants associated with this endpoint.', 'Choose one, either the official OpenAI API or Azure OpenAI API for assistants, not both.'],
  ]}
/>

**Default:** Not specified

**Example:**
```yaml filename="endpoints / azureOpenAI / assistants"
assistants: true
```

## groups

**Key:**
<OptionTable
  options={[
    ['groups', 'Array', 'Configuration for groups of models by geographic location or purpose. Each item in the `groups` array configures a set of models under a certain grouping, often by geographic region or distinct configuration.', ''],
  ]}
/>

**Default:** Not specified

**Note:** [See example above.](#example-configuration)


## Group Object Structure

Each item under `groups` is part of a list of records, each with the following fields:

### group

**Key:**
<OptionTable
  options={[
    ['group', 'String', 'Identifier for a group of models.', ''],
  ]}
/>

**Required:** yes

**Example:**
```yaml filename="endpoints / azureOpenAI / groups / {group_item} / group"
"group": "my-westus"
```

### apiKey

**Key:**
<OptionTable
  options={[
    ['apiKey', 'String', 'The API key for accessing the Azure OpenAI Service.', 'It\'s highly recommended to use a custom env. variable reference for this field, i.e. `${YOUR_VARIABLE}`'],
  ]}
/>

**Required:** yes

**Example:**
```yaml filename="endpoints / azureOpenAI / groups / {group_item} / apiKey"
apiKey: "${WESTUS_API_KEY}"
```

### instanceName

**Key:**
<OptionTable
  options={[
    ['instanceName', 'String', 'Name of the Azure instance.', 'It\'s recommended to use a custom env. variable reference for this field, i.e. `${YOUR_VARIABLE}`'],
  ]}
/>

**Required:** yes

**Example:**
```yaml filename="endpoints / azureOpenAI / groups / {group_item} / instanceName"
instanceName: "my-westus"
```


### version

**Key:**
<OptionTable
  options={[
    ['version', 'String', 'API version.', 'It\'s recommended to use a custom env. variable reference for this field, i.e. `${YOUR_VARIABLE}`'],
  ]}
/>

**Default:** Not specified

**Example:**
```yaml filename="endpoints / azureOpenAI / groups / {group_item} / version"
version: "2023-12-01-preview"
```

### baseURL

**Key:**
<OptionTable
  options={[
    ['baseURL', 'String', 'The base URL for the Azure OpenAI Service.', 'It\'s recommended to use a custom env. variable reference for this field, i.e. `${YOUR_VARIABLE}`'],
  ]}
/>

**Default:** Not specified

**Example:**
```yaml filename="endpoints / azureOpenAI / groups / {group_item} / baseURL"
baseURL: "https://prod.example.com"
```

### additionalHeaders

**Key:**
<OptionTable
  options={[
    ['additionalHeaders', 'Dictionary', 'Additional headers for API requests.', 'It\'s recommended to use a custom env. variable reference for the values of field, as shown in the example. `api-key` header value is sent on every request.'],
  ]}
/>

**Default:** Not specified

**Example:**
```yaml filename="endpoints / azureOpenAI / groups / {group_item} / additionalHeaders"
additionalHeaders:
  X-Custom-Header: ${YOUR_SECRET_CUSTOM_VARIABLE}
```

### serverless

**Key:**
<OptionTable
  options={[
    ['serverless', 'Boolean', 'Indicates the use of a serverless inference endpoint for Azure OpenAI chat completions. When set to `true`, specifies that the group is configured to use serverless inference endpoints as an Azure "Models as a Service" model.', 'More info [here](./azure_openai.md#serverless-inference-endpoints)'],
  ]}
/>

**Default:** Not specified

**Example:**
```yaml filename="endpoints / azureOpenAI / groups / {group_item} / serverless"
serverless: true
```

### addParams

**Key:**
<OptionTable
  options={[
    ['addParams', 'Object/Dictionary', 'Adds additional parameters to requests. Useful for specifying API-specific options.', ''],
  ]}
/>

**Default:** Not specified

**Example:**
```yaml filename="endpoints / azureOpenAI / groups / {group_item} / addParams"
addParams:
  safe_prompt: true
```

### dropParams

**Key:**
<OptionTable
  options={[
    ['dropParams', 'Array/List of Strings', 'Removes [default parameters](#default-parameters) from requests. Excludes specified [default parameters](#default-parameters).', 'For a list of default parameters sent with every request, see the ["Default Parameters"](#default-parameters) Section below.'],
  ]}
/>

**Default:** Not specified

**Example:**
```yaml filename="endpoints / azureOpenAI / groups / {group_item} / dropParams"
dropParams: ["stop", "user", "frequency_penalty", "presence_penalty"]
```

### forcePrompt

**Key:**
<OptionTable
  options={[
    ['forcePrompt', 'Boolean', 'If `true`, sends a `prompt` parameter instead of `messages`. This combines all messages into a single text payload, following OpenAI format, and uses the `/completions` endpoint of your baseURL rather than `/chat/completions`.', ''],
  ]}
/>

**Default:** Not specified

**Example:**
```yaml filename="endpoints / azureOpenAI / groups / {group_item} / forcePrompt"
forcePrompt: false
```

### models

**Key:**
<OptionTable
  options={[
    ['models', '', 'Configuration for individual models within a group. Configures settings for each model, including deployment name and version.', 'Model configurations can adopt the group\'s deployment name and/or version when configured as a boolean (set to `true`) or an object for detailed settings of either of those fields.'],
  ]}
/>

**Default:** Not specified

**Example:**
```yaml filename="endpoints / azureOpenAI / groups / {group_item} / models"
models:
  gpt-4-vision-preview: 
    deploymentName: "arbitrary-deployment-name"
    version: "2024-02-15-preview"
```

## Model Config Structure

Each item under `models` is part of a list of records, either a boolean value or Object:

**When specifying a model as an object:**

An object allows for detailed configuration of the model, including its `deploymentName` and/or `version`. This mode is used for more granular control over the models, especially when working with multiple versions or deployments under one instance or resource group.

**Example**:
```yaml filename="endpoints / azureOpenAI / groups / {group_item} / models / {model_item=Object}"
models:
  gpt-4-vision-preview:
    deploymentName: "gpt-4-vision-preview"
    version: "2024-02-15-preview"
```

**Notes:**
- **Deployment Names** and **Versions** are critical for ensuring that the correct model is used.
    - Double-check these values for accuracy to prevent unexpected behavior.

### deploymentName

**Key:**
<OptionTable
  options={[
    ['deploymentName', 'String', 'The name of the deployment for the model. Identifies the deployment of the model within Azure.', 'This does not have to be the matching OpenAI model name as is convention, but must match the actual name of your deployment on Azure.'],
  ]}
/>

**Required:** yes

**Example:**
```yaml filename="endpoints / azureOpenAI / groups / {group_item} / models / {model_item=Object} / deploymentName"
deploymentName: "gpt-4-vision-preview"
```

## version

**Key:**
<OptionTable
  options={[
    ['version', 'String', 'Specifies the version of the model. Defines the version of the model to be used.', ''],
  ]}
/>

**Required:** yes

**Example:**
```yaml filename="endpoints / azureOpenAI / groups / {group_item} / models / {model_item=Object} / version"
version: "2024-02-15-preview"
```

**Enabling a Model with Default Group Configuration**

**Key:**
<OptionTable
  options={[
    ['models', 'Boolean', 'Enables a model with default group configuration.', 'When a model is enabled (`true`) without using an object, it uses the group\'s configuration values for deployment name and version.'],
  ]}
/>

**Example:**
```yaml filename="endpoints / azureOpenAI / groups / {group_item} / models"
models:
  gpt-4-turbo: true
```

## Default Parameters

Custom endpoints share logic with the OpenAI endpoint, and thus have default parameters tailored to the OpenAI API.

```yaml filename="Default Parameters"
{
  "model": "your-selected-model",
  "temperature": 1,
  "top_p": 1,
  "presence_penalty": 0,
  "frequency_penalty": 0,
  "user": "LibreChat_User_ID",
  "stream": true,
  "messages": [
    {
      "role": "user",
      "content": "hi how are you",
    },
  ],
}
```
### Breakdown
- `model`: The selected model from list of models.
- `temperature`: Defaults to `1` if not provided via preset,
- `top_p`: Defaults to `1` if not provided via preset,
- `presence_penalty`: Defaults to `0` if not provided via preset,
- `frequency_penalty`: Defaults to `0` if not provided via preset,
- `user`: A unique identifier representing your end-user, which can help OpenAI to [monitor and detect abuse](https://platform.openai.com/docs/api-reference/chat/create#chat-create-user).
- `stream`: If set, partial message deltas will be sent, like in ChatGPT. Otherwise, generation will only be available when completed.
- `messages`: [OpenAI format for messages](https://platform.openai.com/docs/api-reference/chat/create#chat-create-messages); the `name` field is added to messages with `system` and `assistant` roles when a custom name is specified via preset.

**Note:** The `max_tokens` field is not sent to use the maximum amount of tokens available, which is default OpenAI API behavior. Some alternate APIs require this field, or it may default to a very low value and your responses may appear cut off; in this case, you should add it to `addParams` field as shown in the [Custom Endpoint Object Structure](#custom-endpoint-object-structure).

## Additional Notes

- Ensure that all URLs and keys are correctly specified to avoid connectivity issues.